{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGYHic3FTha6Wb143Z2D9x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gogumalatte/face-recognizer-webapp/blob/main/%EC%95%88%EB%A9%B4%EC%9D%B8%EC%8B%9D_%EC%9B%B9_%EC%84%9C%EB%B9%84%EC%8A%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 필수 라이브러리 설치\n",
        "- `face_recognition`: 얼굴 인식 및 비교를 위한 핵심 라이브러리\n",
        "- `flask`: 웹 서버 구성\n",
        "- `opencv-python`: 웹캠 영상 처리 및 이미지 캡처\n",
        "- `pyngrok`: Colab 환경에서 외부 공개를 위한 도구"
      ],
      "metadata": {
        "id": "N1COmVOA8-Sf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHcpEE1317ah",
        "outputId": "2bb59284-c2ac-4e31-8c1f-eeb2e2dd703e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-6.0.0-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading flask_cors-6.0.0-py3-none-any.whl (11 kB)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pyngrok, protobuf, numpy, sounddevice, flask-cors, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flask-cors-6.0.0 mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.7 pyngrok-7.2.8 sounddevice-0.5.2\n"
          ]
        }
      ],
      "source": [
        "# 1-1. 필수 패키지 설치\n",
        "!pip install flask flask-cors mediapipe opencv-python-headless pyngrok numpy\n",
        "\n",
        "# 1-2. ngrok 인증 토큰 설정 (ngrok.com에서 무료 계정 생성 후 토큰 발급 필요)\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2wQfPVBCGGvd0mYA96vUepa8w7g_4TsNZesSbc6nvXmV38T3T\")  # 발급받은 토큰으로 변경"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 프론트엔드 정적 파일을 저장할 www 디렉토리를 생성합니다."
      ],
      "metadata": {
        "id": "ixO7e6JFSfMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir www/"
      ],
      "metadata": {
        "id": "15eiLemk6ZDy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 얼굴 인식을 위한 백엔드 코드를 작성합니다.\n",
        "- 사용자의 기존 얼굴 이미지를 로딩하여 face_recognition으로 특징 벡터(encoding)를 추출합니다.\n",
        "- 이후 웹캠 영상에서 인식된 얼굴과 비교할 기준 데이터가 됩니다.\n",
        "- 클라이언트가 접속할 웹 서버를 구성하고,\n",
        "- 실시간 통신(WebSocket)을 통해 얼굴 이미지를 서버로 전달받을 수 있도록 설정합니다.\n",
        "- 클라이언트에서 업로드된 이미지 데이터를 메모리에서 로드하여 얼굴 인식 수행\n",
        "- 등록된 얼굴과 비교 후 일치 여부(True/False)를 반환합니다.\n",
        "- 클라이언트가 WebSocket을 통해 이미지 데이터를 전송하면 서버에서 비교 후 결과를 다시 전송합니다."
      ],
      "metadata": {
        "id": "EBaq9vvcS2mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, request, jsonify, send_from_directory\n",
        "from flask_cors import CORS\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "import io\n",
        "import os\n",
        "import json\n",
        "\n",
        "app = Flask(__name__, template_folder='./www', static_folder='./www', static_url_path='/')\n",
        "CORS(app)\n",
        "\n",
        "# MediaPipe 초기화\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# 얼굴 데이터 저장소 (실제로는 데이터베이스 사용 권장)\n",
        "face_database = {}\n",
        "\n",
        "# 데이터 디렉토리 생성\n",
        "os.makedirs('face_data', exist_ok=True)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return send_from_directory('www', 'index.html')\n",
        "\n",
        "def decode_image(image_data):\n",
        "    # Base64 이미지 디코딩\n",
        "    image_data = image_data.split(',')[1]  # 'data:image/jpeg;base64,' 부분 제거\n",
        "    image_bytes = base64.b64decode(image_data)\n",
        "    nparr = np.frombuffer(image_bytes, np.uint8)\n",
        "    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "\n",
        "def extract_face_features(image):\n",
        "    # MediaPipe로 얼굴 특징점 추출\n",
        "    with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
        "        # RGB로 변환\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # 얼굴 검출\n",
        "        results = face_detection.process(rgb_image)\n",
        "\n",
        "        if results.detections:\n",
        "            faces = []\n",
        "            for detection in results.detections:\n",
        "                bboxC = detection.location_data.relative_bounding_box\n",
        "                ih, iw, _ = image.shape\n",
        "                x = int(bboxC.xmin * iw)\n",
        "                y = int(bboxC.ymin * ih)\n",
        "                w = int(bboxC.width * iw)\n",
        "                h = int(bboxC.height * ih)\n",
        "\n",
        "                # 얼굴 영역 크롭\n",
        "                face_crop = image[y:y+h, x:x+w]\n",
        "\n",
        "                # 얼굴 메쉬로 특징점 추출\n",
        "                with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
        "                    face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "                    face_results = face_mesh.process(face_rgb)\n",
        "\n",
        "                    features = []\n",
        "                    if face_results.multi_face_landmarks:\n",
        "                        for face_landmarks in face_results.multi_face_landmarks:\n",
        "                            # 주요 특징점 추출 (예: 눈, 코, 입 등)\n",
        "                            for landmark in face_landmarks.landmark:\n",
        "                                features.extend([landmark.x, landmark.y, landmark.z])\n",
        "\n",
        "                    faces.append({\n",
        "                        'bbox': {'x': x, 'y': y, 'width': w, 'height': h},\n",
        "                        'features': features\n",
        "                    })\n",
        "\n",
        "            return faces\n",
        "    return None\n",
        "\n",
        "def calculate_similarity(features1, features2):\n",
        "    # 유클리드 거리 기반 유사도 계산\n",
        "    if len(features1) != len(features2):\n",
        "        return 0.0\n",
        "\n",
        "    distance = np.linalg.norm(np.array(features1) - np.array(features2))\n",
        "    # 거리를 유사도로 변환 (0~1)\n",
        "    similarity = max(0, 1 - distance / 10)\n",
        "    return similarity\n",
        "\n",
        "@app.route('/register', methods=['POST'])\n",
        "def register_face():\n",
        "    try:\n",
        "        data = request.json\n",
        "        image = decode_image(data['image'])\n",
        "        name = data['name']\n",
        "\n",
        "        # 얼굴 특징 추출\n",
        "        faces = extract_face_features(image)\n",
        "\n",
        "        if not faces:\n",
        "            return jsonify({\n",
        "                'success': False,\n",
        "                'message': '얼굴을 찾을 수 없습니다.'\n",
        "            })\n",
        "\n",
        "        # 이미 등록된 얼굴 체크\n",
        "        for db_name, db_features in face_database.items():\n",
        "            for face in faces:\n",
        "                similarity = calculate_similarity(face['features'], db_features)\n",
        "                if similarity > 0.95:\n",
        "                    return jsonify({\n",
        "                        'success': False,\n",
        "                        'message': f'이미 등록된 얼굴입니다 (유사도: {similarity*100:.1f}%)'\n",
        "                    })\n",
        "\n",
        "        # 얼굴 등록\n",
        "        face_database[name] = faces[0]['features']\n",
        "\n",
        "        # 데이터 저장\n",
        "        with open(f'face_data/{name}.json', 'w') as f:\n",
        "            json.dump(faces[0]['features'], f)\n",
        "\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'message': f'\"{name}\" 등록 완료'\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            'success': False,\n",
        "            'message': str(e)\n",
        "        })\n",
        "\n",
        "@app.route('/recognize', methods=['POST'])\n",
        "def recognize_face():\n",
        "    try:\n",
        "        data = request.json\n",
        "        image = decode_image(data['image'])\n",
        "\n",
        "        # 얼굴 특징 추출\n",
        "        faces = extract_face_features(image)\n",
        "\n",
        "        if not faces:\n",
        "            return jsonify({\n",
        "                'success': False,\n",
        "                'message': '얼굴을 찾을 수 없습니다.'\n",
        "            })\n",
        "\n",
        "        result = {'faces': []}\n",
        "\n",
        "        for face in faces:\n",
        "            best_match = None\n",
        "            best_similarity = 0\n",
        "\n",
        "            for name, db_features in face_database.items():\n",
        "                similarity = calculate_similarity(face['features'], db_features)\n",
        "                if similarity > best_similarity and similarity > 0.7:\n",
        "                    best_similarity = similarity\n",
        "                    best_match = name\n",
        "\n",
        "            face_result = {\n",
        "                'x': face['bbox']['x'],\n",
        "                'y': face['bbox']['y'],\n",
        "                'width': face['bbox']['width'],\n",
        "                'height': face['bbox']['height'],\n",
        "                'name': best_match,\n",
        "                'confidence': best_similarity\n",
        "            }\n",
        "            result['faces'].append(face_result)\n",
        "\n",
        "        return jsonify({\n",
        "            'success': True,\n",
        "            'result': result\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            'success': False,\n",
        "            'message': str(e)\n",
        "        })\n",
        "\n",
        "# 저장된 얼굴 데이터 로드\n",
        "def load_face_data():\n",
        "    global face_database\n",
        "    face_data_dir = 'face_data'\n",
        "\n",
        "    if os.path.exists(face_data_dir):\n",
        "        for filename in os.listdir(face_data_dir):\n",
        "            if filename.endswith('.json'):\n",
        "                name = filename[:-5]  # .json 제거\n",
        "                with open(os.path.join(face_data_dir, filename), 'r') as f:\n",
        "                    face_database[name] = json.load(f)\n",
        "\n",
        "# 앱 시작 시 데이터 로드\n",
        "load_face_data()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=3000, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHjmU7H25vBp",
        "outputId": "db1f04ec-1c88-4013-ae78-4526df9a6f6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 사용자와 상호 작용을 할 프론트엔드 코드를 작성합니다.\n",
        "## HTML + JS"
      ],
      "metadata": {
        "id": "T7eSHQKKTSEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile www/index.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"ko\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>안면인식 시스템</title>\n",
        "    <script src=\"https://unpkg.com/react@17/umd/react.development.js\"></script>\n",
        "    <script src=\"https://unpkg.com/react-dom@17/umd/react-dom.development.js\"></script>\n",
        "    <script src=\"https://unpkg.com/@babel/standalone/babel.min.js\"></script>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 20px;\n",
        "            background-color: #f0f0f0;\n",
        "        }\n",
        "        .container {\n",
        "            max-width: 800px;\n",
        "            margin: 0 auto;\n",
        "            background: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        video, canvas {\n",
        "            max-width: 100%;\n",
        "            background: #000;\n",
        "            margin: 10px 0;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        button {\n",
        "            padding: 10px 20px;\n",
        "            margin: 5px;\n",
        "            font-size: 16px;\n",
        "            cursor: pointer;\n",
        "            background: #4CAF50;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        button:hover {\n",
        "            background: #45a049;\n",
        "        }\n",
        "        .info-panel {\n",
        "            margin-top: 20px;\n",
        "            padding: 10px;\n",
        "            background: #e7f3fe;\n",
        "            border-left: 6px solid #2196F3;\n",
        "        }\n",
        "        .error {\n",
        "            color: red;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "        .success {\n",
        "            color: green;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"root\"></div>\n",
        "\n",
        "    <script type=\"text/babel\">\n",
        "        const FaceRecognitionApp = () => {\n",
        "            const [stream, setStream] = React.useState(null);\n",
        "            const [cameraType, setCameraType] = React.useState('user');\n",
        "            const [message, setMessage] = React.useState('');\n",
        "            const [recognitionResult, setRecognitionResult] = React.useState(null);\n",
        "            const [isRegistering, setIsRegistering] = React.useState(false);\n",
        "            const [personName, setPersonName] = React.useState('');\n",
        "\n",
        "            const videoRef = React.useRef(null);\n",
        "            const canvasRef = React.useRef(null);\n",
        "\n",
        "            React.useEffect(() => {\n",
        "                startCamera();\n",
        "                return () => {\n",
        "                    if (stream) {\n",
        "                        stream.getTracks().forEach(track => track.stop());\n",
        "                    }\n",
        "                };\n",
        "            }, [cameraType]);\n",
        "\n",
        "            const startCamera = async () => {\n",
        "                try {\n",
        "                    if (stream) {\n",
        "                        stream.getTracks().forEach(track => track.stop());\n",
        "                    }\n",
        "\n",
        "                    const newStream = await navigator.mediaDevices.getUserMedia({\n",
        "                        video: { facingMode: cameraType },\n",
        "                        audio: false\n",
        "                    });\n",
        "\n",
        "                    setStream(newStream);\n",
        "                    if (videoRef.current) {\n",
        "                        videoRef.current.srcObject = newStream;\n",
        "                    }\n",
        "                } catch (err) {\n",
        "                    setMessage(`카메라 접근 오류: ${err.message}`);\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const toggleCamera = () => {\n",
        "                setCameraType(prev => prev === 'user' ? 'environment' : 'user');\n",
        "            };\n",
        "\n",
        "            const captureImage = () => {\n",
        "                const canvas = canvasRef.current;\n",
        "                const video = videoRef.current;\n",
        "\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "\n",
        "                const context = canvas.getContext('2d');\n",
        "                context.drawImage(video, 0, 0);\n",
        "\n",
        "                return canvas.toDataURL('image/jpeg', 0.8);\n",
        "            };\n",
        "\n",
        "            const registerFace = async () => {\n",
        "                if (!personName.trim()) {\n",
        "                    setMessage('이름을 입력해주세요.');\n",
        "                    return;\n",
        "                }\n",
        "\n",
        "                try {\n",
        "                    setIsRegistering(true);\n",
        "                    const imageData = captureImage();\n",
        "\n",
        "                    const response = await fetch('/register', {\n",
        "                        method: 'POST',\n",
        "                        headers: {\n",
        "                            'Content-Type': 'application/json',\n",
        "                        },\n",
        "                        body: JSON.stringify({\n",
        "                            image: imageData,\n",
        "                            name: personName\n",
        "                        }),\n",
        "                    });\n",
        "\n",
        "                    const data = await response.json();\n",
        "\n",
        "                    if (data.success) {\n",
        "                        setMessage(`안면 등록 성공: ${data.message}`);\n",
        "                        setPersonName('');\n",
        "                    } else {\n",
        "                        setMessage(`안면 등록 실패: ${data.message}`);\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    setMessage(`등록 오류: ${error.message}`);\n",
        "                } finally {\n",
        "                    setIsRegistering(false);\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const recognizeFace = async () => {\n",
        "                try {\n",
        "                    const imageData = captureImage();\n",
        "\n",
        "                    const response = await fetch('/recognize', {\n",
        "                        method: 'POST',\n",
        "                        headers: {\n",
        "                            'Content-Type': 'application/json',\n",
        "                        },\n",
        "                        body: JSON.stringify({\n",
        "                            image: imageData\n",
        "                        }),\n",
        "                    });\n",
        "\n",
        "                    const data = await response.json();\n",
        "\n",
        "                    if (data.success) {\n",
        "                        setRecognitionResult(data.result);\n",
        "                        drawBoundingBox(data.result);\n",
        "                        setMessage('안면 인식 성공!');\n",
        "                    } else {\n",
        "                        setMessage(`안면 인식 실패: ${data.message}`);\n",
        "                        setRecognitionResult(null);\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    setMessage(`인식 오류: ${error.message}`);\n",
        "                }\n",
        "            };\n",
        "\n",
        "            const drawBoundingBox = (result) => {\n",
        "                const canvas = canvasRef.current;\n",
        "                const video = videoRef.current;\n",
        "                const context = canvas.getContext('2d');\n",
        "\n",
        "                // 원본 이미지 다시 그리기\n",
        "                context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "                // 바운딩 박스 그리기\n",
        "                if (result.faces && result.faces.length > 0) {\n",
        "                    result.faces.forEach(face => {\n",
        "                        context.strokeStyle = '#00ff00';\n",
        "                        context.lineWidth = 3;\n",
        "                        context.strokeRect(face.x, face.y, face.width, face.height);\n",
        "\n",
        "                        // 이름 표시\n",
        "                        if (face.name) {\n",
        "                            context.fillStyle = '#00ff00';\n",
        "                            context.font = '20px Arial';\n",
        "                            context.fillText(face.name, face.x, face.y - 5);\n",
        "                        }\n",
        "                    });\n",
        "                }\n",
        "            };\n",
        "\n",
        "            return (\n",
        "                <div className=\"container\">\n",
        "                    <h1>안면인식 시스템</h1>\n",
        "\n",
        "                    <div>\n",
        "                        <video\n",
        "                            ref={videoRef}\n",
        "                            autoPlay\n",
        "                            playsInline\n",
        "                            style={{ display: 'block' }}\n",
        "                        />\n",
        "                        <canvas\n",
        "                            ref={canvasRef}\n",
        "                            style={{ display: 'none' }}\n",
        "                        />\n",
        "                    </div>\n",
        "\n",
        "                    <div>\n",
        "                        <button onClick={toggleCamera}>\n",
        "                            카메라 전환 ({cameraType === 'user' ? '전면' : '후면'})\n",
        "                        </button>\n",
        "                    </div>\n",
        "\n",
        "                    <div>\n",
        "                        <h3>안면 등록</h3>\n",
        "                        <input\n",
        "                            type=\"text\"\n",
        "                            value={personName}\n",
        "                            onChange={(e) => setPersonName(e.target.value)}\n",
        "                            placeholder=\"이름 입력\"\n",
        "                            style={{ padding: '10px', marginRight: '10px' }}\n",
        "                        />\n",
        "                        <button\n",
        "                            onClick={registerFace}\n",
        "                            disabled={isRegistering}\n",
        "                        >\n",
        "                            {isRegistering ? '등록 중...' : '안면 등록'}\n",
        "                        </button>\n",
        "                    </div>\n",
        "\n",
        "                    <div>\n",
        "                        <button onClick={recognizeFace}>\n",
        "                            안면 인식\n",
        "                        </button>\n",
        "                    </div>\n",
        "\n",
        "                    {message && (\n",
        "                        <div className={message.includes('성공') ? 'success' : 'error'}>\n",
        "                            {message}\n",
        "                        </div>\n",
        "                    )}\n",
        "\n",
        "                    {recognitionResult && recognitionResult.faces && (\n",
        "                        <div className=\"info-panel\">\n",
        "                            <h3>인식 결과</h3>\n",
        "                            {recognitionResult.faces.map((face, index) => (\n",
        "                                <div key={index}>\n",
        "                                    <p>이름: {face.name || '알 수 없음'}</p>\n",
        "                                    <p>신뢰도: {(face.confidence * 100).toFixed(1)}%</p>\n",
        "                                    <p>위치: ({face.x}, {face.y})</p>\n",
        "                                    <p>크기: {face.width}x{face.height}</p>\n",
        "                                </div>\n",
        "                            ))}\n",
        "                        </div>\n",
        "                    )}\n",
        "                </div>\n",
        "            );\n",
        "        };\n",
        "\n",
        "        ReactDOM.render(<FaceRecognitionApp />, document.getElementById('root'));\n",
        "    </script>\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TO-gjAD2E1e",
        "outputId": "c8e21155-4ea6-41b4-d5fb-bb10dc0fc1b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing www/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 한 번에 위 서버를 실행하고 접근 URL을 여는 실행 스크립트를 작성합니다."
      ],
      "metadata": {
        "id": "E_YUQnyoTcoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_server.py\n",
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Flask 서버 시작\n",
        "server_process = subprocess.Popen([\"python\", \"app.py\"])\n",
        "print(\"Flask 서버가 시작되었습니다.\")\n",
        "\n",
        "# ngrok 터널 생성\n",
        "http_tunnel = ngrok.connect(3000)\n",
        "print(f\"ngrok 터널이 생성되었습니다: {http_tunnel.public_url}\")\n",
        "print(f\"모바일에서 접속하세요: {http_tunnel.public_url}\")\n",
        "\n",
        "try:\n",
        "    # 앱이 계속 실행되도록 대기\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    # 종료 시 프로세스 정리\n",
        "    server_process.terminate()\n",
        "    ngrok.kill()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8zc7Fre56y8",
        "outputId": "779a2582-18c2-4494-f0f8-c050a79026e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 5단계에서 생성한 스크립트를 실행합니다. (서버를 실행)"
      ],
      "metadata": {
        "id": "HtYhmF-ET3XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 서버 실행\n",
        "!python run_server.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHwh-bky59HR",
        "outputId": "f3d76f94-d2ee-4bf8-af5f-acaf25ab9c2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask 서버가 시작되었습니다.\n",
            "ngrok 터널이 생성되었습니다: https://3379-34-125-46-233.ngrok-free.app\n",
            "모바일에서 접속하세요: https://3379-34-125-46-233.ngrok-free.app\n",
            "2025-05-19 11:31:02.232205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747654262.264696    2895 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747654262.274529    2895 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 11:31:02.304623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            " * Serving Flask app 'app'\n",
            " * Debug mode: on\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:3000\n",
            " * Running on http://172.28.0.12:3000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            " * Restarting with stat\n",
            "2025-05-19 11:31:06.581907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747654266.601289    2952 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747654266.607059    2952 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            " * Debugger is active!\n",
            " * Debugger PIN: 347-788-323\n",
            "127.0.0.1 - - [19/May/2025 11:31:10] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [19/May/2025 11:31:11] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1747654325.502122    3218 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1747654325.525867    3226 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1747654325.538746    3226 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1747654325.541317    3225 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
            "127.0.0.1 - - [19/May/2025 11:32:05] \"POST /register HTTP/1.1\" 200 -\n",
            "W0000 00:00:1747654329.277533    3240 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1747654329.288277    3243 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1747654329.299011    3243 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "127.0.0.1 - - [19/May/2025 11:32:09] \"POST /recognize HTTP/1.1\" 200 -\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/run_server.py\", line 17, in <module>\n",
            "    time.sleep(1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/run_server.py\", line 21, in <module>\n",
            "    ngrok.kill()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\", line 494, in kill\n",
            "    process.kill_process(pyngrok_config.ngrok_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\", line 287, in kill_process\n",
            "    ngrok_process.proc.wait()\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1264, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2053, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2011, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MY3gD-d6vqn",
        "outputId": "c3a7a8dd-181a-4900-eaab-a93320d2c29e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 1s (84.8 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYn-TTv_60CP",
        "outputId": "0ba6a179-6b84-4bba-82b2-b0c91cb6cb38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m.\u001b[0m\n",
            "├── \u001b[00mapp.py\u001b[0m\n",
            "├── \u001b[01;34mface_data\u001b[0m\n",
            "│   └── \u001b[00m최기영.json\u001b[0m\n",
            "├── \u001b[00mrun_server.py\u001b[0m\n",
            "├── \u001b[01;34msample_data\u001b[0m\n",
            "│   ├── \u001b[01;32manscombe.json\u001b[0m\n",
            "│   ├── \u001b[00mcalifornia_housing_test.csv\u001b[0m\n",
            "│   ├── \u001b[00mcalifornia_housing_train.csv\u001b[0m\n",
            "│   ├── \u001b[00mmnist_test.csv\u001b[0m\n",
            "│   ├── \u001b[00mmnist_train_small.csv\u001b[0m\n",
            "│   └── \u001b[01;32mREADME.md\u001b[0m\n",
            "└── \u001b[01;34mwww\u001b[0m\n",
            "    └── \u001b[00mindex.html\u001b[0m\n",
            "\n",
            "3 directories, 10 files\n"
          ]
        }
      ]
    }
  ]
}